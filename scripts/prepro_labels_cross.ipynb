{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset_subset_XXX.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nakamura/project/python3_selfsequential/vg')\n",
    "import visual_genome.local as vg\n",
    "dir = '/mnt/poplin/share/dataset/visualgenome'\n",
    "all_images = vg.get_all_image_data(dir)\n",
    "all_discriptions = vg.get_all_region_descriptions(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_discriptions[36025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from visual_genome import api\n",
    "from PIL import Image as PIL_Image\n",
    "import requests\n",
    "import pdb\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/nakamura/project/self_seqential/data/dataset_coco.json', 'r')\n",
    "info_base = json.load(f)\n",
    "\n",
    "info_vg = {}\n",
    "info_vg['dataset'] = 'vg'\n",
    "info_vg['images'] = []\n",
    "\n",
    "info_coco = {}\n",
    "info_coco['dataset'] = 'coco'\n",
    "info_coco['images'] = []\n",
    "\n",
    "info_coco_vg = {}\n",
    "info_coco_vg['dataset'] = 'coco and vg'\n",
    "info_coco_vg['images'] = []\n",
    "\n",
    "info_vg_larger = {}\n",
    "info_vg_larger['dataset'] = 'vg_larger'\n",
    "info_vg_larger['images'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "順番が適当な場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "for i, img in enumerate(info_base['images']):\n",
    "    for j , vg_img in enumerate(all_images):\n",
    "        if img['cocoid'] == vg_img.coco_id:\n",
    "            img_info = {}\n",
    "            img_info['filepath'] = img['filepath']\n",
    "            img_info['sentids'] = img['sentids']\n",
    "            img_info['filename'] = img['filename']\n",
    "            img_info['imgid'] = img['imgid']\n",
    "            img_info['split'] = img['split']\n",
    "            img_info['cocoid'] = img['cocoid']\n",
    "            \n",
    "            sentenses_coco = img['sentences']\n",
    "            \n",
    "            sentenses_vg = []\n",
    "            for region in all_discriptions[j]:\n",
    "                sent_info = {}\n",
    "                sent_info['imgid'] = i\n",
    "                sent_info['raw'] = region.phrase\n",
    "                pdb.set_trace()\n",
    "                sent_info['tokens'] = region.phrase.split()\n",
    "                sentenses_vg.append(sent_info)\n",
    "                \n",
    "            sentenses = sentenses_vg + sentenses_coco\n",
    "            img_info_coco_vg = copy.copy(img_info)\n",
    "            img_info_coco = copy.copy(img_info)\n",
    "            img_info_vg = copy.copy(img_info)\n",
    "            \n",
    "            img_info_coco_vg['sentences'] = sentenses\n",
    "            info_coco_vg['images'].append(img_info_coco_vg)\n",
    "            \n",
    "            img_info_vg['sentences'] = sentenses_vg\n",
    "            info_vg['images'].append(img_info_vg)\n",
    "            \n",
    "            img_info_coco['sentences'] = sentenses_coco\n",
    "            info_coco['images'].append(img_info_coco)\n",
    "            \n",
    "            print(len(img_info_coco_vg['sentences']))\n",
    "            print(len(img_info_coco['sentences']))\n",
    "            print(len(img_info_vg['sentences']))\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual genome の領域の順番が決まっている場合．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_set_regions_nodup = json.load(open('/mnt/workspace2018/nakamura/selfsequential/data/marged_set_larger_nodup.json', 'r'))\n",
    "# all_set_regions_nodup = json.load(open('/mnt/workspace2018/nakamura/selfsequential/data/marged_set_allvg_07.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_set_regions_nodup = json.load(open('/mnt/workspace2018/nakamura/selfsequential/data/marged_set_larger_morethan3.json', 'r'))\n",
    "all_set_regions_nodup_flg = all_set_regions_nodup['flg']\n",
    "all_set_regions_nodup = all_set_regions_nodup['maged_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_tables = json.load(open('/mnt/workspace2018/nakamura/selfsequential/data/cor_tables.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# cocoとの共通の場合\n",
    "import copy\n",
    "\n",
    "max_att_length = 88\n",
    "imgs = info_base['images']\n",
    "for num, table in enumerate(cor_tables):\n",
    "    i = table[0]\n",
    "    j = table[1]\n",
    "    img = imgs[i]\n",
    "    vg_image = all_images[j]\n",
    "\n",
    "    img_info = {}\n",
    "    img_info['filepath'] = img['filepath']\n",
    "    img_info['sentids'] = img['sentids']\n",
    "    img_info['filename'] = img['filename']\n",
    "    img_info['imgid'] = img['imgid']\n",
    "    img_info['split'] = img['split']\n",
    "    img_info['cocoid'] = img['cocoid']\n",
    "    \n",
    "    sentenses_coco = img['sentences']\n",
    "\n",
    "    sentenses_vg = []\n",
    "    for k_num, key in enumerate(all_set_regions_nodup[num].keys()):\n",
    "        if k_num < max_att_length:\n",
    "#             print(k_num)\n",
    "            region_list = all_set_regions_nodup[num][key]\n",
    "\n",
    "            for r_num in region_list:\n",
    "                region = all_discriptions[j][r_num]\n",
    "                sent_info = {}\n",
    "                sent_info['imgid'] = i\n",
    "                sent_info['raw'] = region.phrase.lower()\n",
    "                sent_info['tokens'] = region.phrase.lower().split()\n",
    "                sentenses_vg.append(sent_info)\n",
    "        \n",
    "    sentenses = sentenses_vg + sentenses_coco\n",
    "\n",
    "    img_info_coco = copy.copy(img_info)\n",
    "    img_info_vg_larger = copy.copy(img_info)\n",
    "\n",
    "    img_info_vg_larger['sentences'] = sentenses_vg\n",
    "    info_vg_larger['images'].append(img_info_vg_larger)\n",
    "\n",
    "    img_info_coco['sentences'] = sentenses_coco\n",
    "    info_coco['images'].append(img_info_coco)\n",
    "    \n",
    "print(len(img_info_coco['sentences']))\n",
    "print(len(img_info_vg_larger['sentences']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(info_vg_larger, open('/mnt/workspace2018/nakamura/selfsequential/data/dataset_allvg07_larger_morethan3gt.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual genome のsplit の決定\n",
    "val_test_split_id = np.random.permutation(np.arange(len(all_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_region_num = 0\n",
    "for num in range(len(all_set_regions_nodup)):\n",
    "    region_num = len(all_set_regions_nodup[num].keys()) + 1\n",
    "    if max_region_num < region_num:\n",
    "        max_region_num = region_num\n",
    "print(max_region_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual genomeのみの場合\n",
    "vg_dataset = json.load(open('/mnt/workspace2018/nakamura/selfsequential/data/dataset_subset_vg_larger_all.json'))\n",
    "image_dir = '/mnt/workspace2018/nakamura/vg_images/VG_100K'\n",
    "\n",
    "import os\n",
    "import copy\n",
    "\n",
    "imgs = info_base['images']\n",
    "for num, vg_image in enumerate(all_images):\n",
    "    \n",
    "    if os.path.exists(image_dir + '/' + str(vg_image.id) + '.jpg'):\n",
    "#         I = skimage.io.imread(image_dir + '/' + str(vg_image.id) + '.jpg')\n",
    "        filepath = 'VG_100K'\n",
    "    else:\n",
    "#         I = skimage.io.imread(image_dir + '_2/' + str(vg_image.id) + '.jpg')\n",
    "        filepath = 'VG_100K_2'\n",
    "\n",
    "    img_info = {}\n",
    "    img_info['filepath'] = filepath\n",
    "    img_info['sentids'] = num\n",
    "    img_info['filename'] = str(vg_image.id)\n",
    "    img_info['imgid'] = str(vg_image.id)\n",
    "    if num in val_test_split_id[:5000]:\n",
    "        img_info['split'] = 'val'\n",
    "    elif num in val_test_split_id[5000:10000]:\n",
    "        img_info['split'] = 'test'\n",
    "    else:\n",
    "        img_info['split'] = 'train'\n",
    "    img_info['cocoid'] = str(vg_image.id)\n",
    "\n",
    "    sentenses_vg = []\n",
    "    for k_num, key in enumerate(all_set_regions_nodup[num].keys()):\n",
    "        region_list = all_set_regions_nodup[num][key]\n",
    "        \n",
    "        region = all_discriptions[num][int(key)]\n",
    "        sent_info = {}\n",
    "        sent_info['imgid'] = num\n",
    "        sent_info['raw'] = region.phrase.lower()\n",
    "        sent_info['tokens'] = region.phrase.lower().split()\n",
    "        sentenses_vg.append(sent_info)\n",
    "        \n",
    "        for r_num in region_list:\n",
    "            region = all_discriptions[num][r_num]\n",
    "            sent_info = {}\n",
    "            sent_info['imgid'] = num\n",
    "            sent_info['raw'] = region.phrase.lower()\n",
    "            sent_info['tokens'] = region.phrase.lower().split()\n",
    "            sentenses_vg.append(sent_info)\n",
    "        \n",
    "    sentenses = sentenses_vg\n",
    "\n",
    "    img_info_vg = copy.copy(img_info)\n",
    "    img_info_vg['sentences'] = sentenses_vg\n",
    "    info_vg['images'].append(img_info_vg)\n",
    "    \n",
    "    if num % 1000 == 0:\n",
    "        print('processing %d/%d (%.2f%% done)' % (num, len(all_images), num*100.0/len(all_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(info_vg, open('/mnt/workspace2018/nakamura/selfsequential/data/dataset_allvg07_larger.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(info_vg_larger, open('/mnt/workspace2018/nakamura/selfsequential/data/dataset_subset_vg_larger.json', 'w'))\n",
    "json.dump(info_coco, open('/mnt/workspace2018/nakamura/selfsequential/data/dataset_subset_coco_larger.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make json and labelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from random import shuffle, seed\n",
    "import string\n",
    "# non-standard dependencies:\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import skimage.io\n",
    "from PIL import Image\n",
    "import pdb\n",
    "import prepro_labels as labels\n",
    "\n",
    "import easydict\n",
    "# args = easydict.EasyDict({\n",
    "#         \"input_json\": '/home/nakamura/project/self_seqential/data/dataset_subset_coco_and_vg_.json',\n",
    "#         \"output_json\": '/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_mscoco_and_vg_.json',\n",
    "#         \"output_h5\": '/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_mscoco_and_vg_',\n",
    "#         \"image_root\": '',\n",
    "#         \"max_length\": 30,\n",
    "#         \"word_count_threshold\": 5\n",
    "# })\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "        \"input_json\": '/home/nakamura/project/self_seqential/data/dataset_subset_coco_and_vg_.json',\n",
    "        \"output_json\": '/mnt/poplin/share/dataset/MSCOCO/sample.json',\n",
    "        \"output_h5\": '/mnt/poplin/share/dataset/MSCOCO/sample',\n",
    "        \"image_root\": '',\n",
    "        \"max_length\": 30,\n",
    "        \"word_count_threshold\": 5\n",
    "})\n",
    "\n",
    "# args_vg = easydict.EasyDict({\n",
    "#         \"input_json\": '/home/nakamura/project/self_seqential/data/dataset_subset_vg_.json',\n",
    "#         \"output_json\": '/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_vg_.json',\n",
    "#         \"output_h5\": '/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_vg_',\n",
    "#         \"image_root\": '',\n",
    "#         \"max_length\": 30,\n",
    "#         \"word_count_threshold\": 5\n",
    "# })\n",
    "\n",
    "args_vg = easydict.EasyDict({\n",
    "        \"input_json\": '/mnt/workspace2018/nakamura/selfsequential/data/dataset_subset_vg_larger_all.json',\n",
    "        \"output_json\": '/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_vg_larger_all.json',\n",
    "        \"output_h5\": '/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_vg_larger_all',\n",
    "        \"image_root\": '',\n",
    "        \"max_length\": 30,\n",
    "        \"word_count_threshold\": 5\n",
    "})\n",
    "\n",
    "# args_vg = easydict.EasyDict({\n",
    "#         \"input_json\": '/mnt/workspace2018/nakamura/selfsequential/data/dataset_allvg07_larger.json',\n",
    "#         \"output_json\": '/mnt/workspace2018/nakamura/selfsequential/data/cocotalk_allvg07_larger.json',\n",
    "#         \"output_h5\": '/mnt/workspace2018/nakamura/selfsequential/data/cocotalk_allvg07_larger',\n",
    "#         \"image_root\": '',\n",
    "#         \"max_length\": 30,\n",
    "#         \"word_count_threshold\": 5\n",
    "# })\n",
    "\n",
    "args_mscoco = easydict.EasyDict({\n",
    "        \"input_json\": '/mnt/workspace2018/nakamura/selfsequential/data/dataset_subset_coco_larger.json',\n",
    "        \"output_json\": '/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_mscoco_larger.json',\n",
    "        \"output_h5\": '/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_mscoco_larger',\n",
    "        \"image_root\": '',\n",
    "        \"max_length\": 30,\n",
    "        \"word_count_threshold\": 5\n",
    "})\n",
    "\n",
    "args_sew = easydict.EasyDict({\n",
    "        \"input_json\": '/mnt/poplin/share/dataset/simple_english_wikipedia/dataset_sew_unk2_l0.json',\n",
    "        \"output_json\": '/mnt/poplin/share/dataset/simple_english_wikipedia/sew_talk.json',\n",
    "        \"output_h5\": '/mnt/poplin/share/dataset/simple_english_wikipedia/sew_talk',\n",
    "        \"image_root\": '',\n",
    "        \"max_length\": 30,\n",
    "        \"word_count_threshold\": 0\n",
    "})\n",
    "\n",
    "args_3gt = easydict.EasyDict({\n",
    "        \"input_json\": '/mnt/workspace2018/nakamura/selfsequential/data/dataset_allvg07_larger_morethan3gt.json',\n",
    "        \"output_json\": '/mnt/workspace2018/nakamura/selfsequential/data/cocotalk_subset_vg_larger_morethan3gt.json',\n",
    "        \"output_h5\": '/mnt/workspace2018/nakamura/selfsequential/data/cocotalk_subset_vg_larger_morethan3gt_label_all.h5',\n",
    "        \"image_root\": '',\n",
    "        \"max_length\": 30,\n",
    "        \"word_count_threshold\": 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dataset = json.load(open('/mnt/workspace2018/nakamura/selfsequential/data/dataset_subset_vg_larger.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_json = json.load(open('/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_mscoco_larger.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw = info_json['ix_to_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = ''\n",
    "for ix in array:\n",
    "    if ix > 0:\n",
    "        st += itw[str(ix)]\n",
    "        st += ' '\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_json['images'][37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for info in info_dataset['images'][37]['sentences']:\n",
    "    print(count, info['raw'])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dets = json.load(open('/mnt/workspace2018/nakamura/selfsequential/data/region_dets_larger.json', 'r'))\n",
    "all_dets = json.load(open('/mnt/workspace2018/nakamura/selfsequential/data/region_dets_allvg_07.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for info in all_dets[37]:\n",
    "    print(count, info)\n",
    "    count += 1\n",
    "# all_dets[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(all_images):\n",
    "    if img.coco_id == 480985:\n",
    "        print(all_discriptions[i][29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing vocab\n",
    "\n",
    "imgs = json.load(open(args['input_json'], 'r'))\n",
    "imgs = imgs['images']\n",
    "\n",
    "imgs_vg = json.load(open(args_vg['input_json'], 'r'))\n",
    "imgs_vg = imgs_vg['images']\n",
    "\n",
    "imgs_coco = json.load(open(args_mscoco['input_json'], 'r'))\n",
    "imgs_coco = imgs_coco['images']\n",
    "\n",
    "seed(123) # make reproducible\n",
    "\n",
    "# create the vocab\n",
    "vocab = labels.build_vocab(imgs, args)\n",
    "itow = {i+1:w for i,w in enumerate(vocab)} # a 1-indexed vocab translation table\n",
    "wtoi = {w:i+1 for i,w in enumerate(vocab)} # inverse table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info = json.load(open('/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_vg_larger.json', 'r'))\n",
    "ix_to_word = info['ix_to_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtoi = {}\n",
    "for k in ix_to_word.keys():\n",
    "    wtoi[ix_to_word[k]] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_vg = json.load(open(args_vg['input_json'], 'r'))\n",
    "# imgs_vg = imgs_vg['images']\n",
    "imgs_vg = json.load(open(args_3gt['input_json'], 'r'))\n",
    "imgs_vg = imgs_vg['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use more than 3 gt, selsect use caption\n",
    "info_img = info['images']\n",
    "info_morethan3gt = {}\n",
    "info_img_morethan3gt = []\n",
    "for i in range(len(info_img)):\n",
    "    element = {}\n",
    "    if info_img[i]['split'] == 'train' or info_img[i]['split'] == 'restval':\n",
    "        if all_set_regions_nodup_flg[i] == 1:\n",
    "            info_img_morethan3gt.append(info_img[i])\n",
    "        else:\n",
    "            info_img[i]['split'] = 'nouse'\n",
    "            info_img_morethan3gt.append(info_img[i])\n",
    "    else:\n",
    "        info_img_morethan3gt.append(info_img[i])\n",
    "info_morethan3gt['images'] = info_img_morethan3gt\n",
    "info_morethan3gt['ix_to_word'] = ix_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(info_morethan3gt, open('/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_vg_larger_morethan3gt.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_sew = json.load(open(args_sew['input_json'], 'r'))\n",
    "imgs_sew = imgs_sew['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0/51197 (0.00% done)\n",
      "processing 1000/51197 (1.95% done)\n",
      "processing 2000/51197 (3.91% done)\n",
      "processing 3000/51197 (5.86% done)\n",
      "processing 4000/51197 (7.81% done)\n",
      "processing 5000/51197 (9.77% done)\n",
      "processing 6000/51197 (11.72% done)\n",
      "processing 7000/51197 (13.67% done)\n",
      "processing 8000/51197 (15.63% done)\n",
      "[]\n",
      "['UNK']\n",
      "processing 9000/51197 (17.58% done)\n",
      "processing 10000/51197 (19.53% done)\n",
      "processing 11000/51197 (21.49% done)\n",
      "processing 12000/51197 (23.44% done)\n",
      "processing 13000/51197 (25.39% done)\n",
      "[]\n",
      "['UNK']\n",
      "processing 14000/51197 (27.35% done)\n",
      "processing 15000/51197 (29.30% done)\n",
      "processing 16000/51197 (31.25% done)\n",
      "processing 17000/51197 (33.21% done)\n",
      "processing 18000/51197 (35.16% done)\n",
      "processing 19000/51197 (37.11% done)\n",
      "processing 20000/51197 (39.06% done)\n",
      "processing 21000/51197 (41.02% done)\n",
      "processing 22000/51197 (42.97% done)\n",
      "processing 23000/51197 (44.92% done)\n",
      "processing 24000/51197 (46.88% done)\n",
      "processing 25000/51197 (48.83% done)\n",
      "processing 26000/51197 (50.78% done)\n",
      "processing 27000/51197 (52.74% done)\n",
      "processing 28000/51197 (54.69% done)\n",
      "processing 29000/51197 (56.64% done)\n",
      "processing 30000/51197 (58.60% done)\n",
      "processing 31000/51197 (60.55% done)\n",
      "processing 32000/51197 (62.50% done)\n",
      "processing 33000/51197 (64.46% done)\n",
      "processing 34000/51197 (66.41% done)\n",
      "processing 35000/51197 (68.36% done)\n",
      "processing 36000/51197 (70.32% done)\n",
      "[]\n",
      "['UNK']\n",
      "processing 37000/51197 (72.27% done)\n",
      "processing 38000/51197 (74.22% done)\n",
      "processing 39000/51197 (76.18% done)\n",
      "processing 40000/51197 (78.13% done)\n",
      "processing 41000/51197 (80.08% done)\n",
      "processing 42000/51197 (82.04% done)\n",
      "processing 43000/51197 (83.99% done)\n",
      "processing 44000/51197 (85.94% done)\n",
      "processing 45000/51197 (87.90% done)\n",
      "processing 46000/51197 (89.85% done)\n",
      "processing 47000/51197 (91.80% done)\n",
      "processing 48000/51197 (93.76% done)\n",
      "processing 49000/51197 (95.71% done)\n",
      "processing 50000/51197 (97.66% done)\n",
      "processing 51000/51197 (99.62% done)\n",
      "encoded captions to array of size  (2204527, 30)\n"
     ]
    }
   ],
   "source": [
    "# L, label_start_ix, label_end_ix, label_length = labels.encode_captions(imgs, args, wtoi)\n",
    "\n",
    "# for img in imgs_coco:\n",
    "#     img['final_captions'] = []\n",
    "#     for sent in img['sentences']:\n",
    "#         txt = sent['tokens']\n",
    "#         caption = [w if w in wtoi.keys() else 'UNK' for w in txt]\n",
    "#         img['final_captions'].append(caption)\n",
    "\n",
    "# L_coco, label_start_ix_coco, label_end_ix_coco, label_length_coco = labels.encode_captions(imgs_coco, args_mscoco, wtoi)\n",
    "\n",
    "for num, img in enumerate(imgs_vg):\n",
    "    img['final_captions'] = []\n",
    "    for sent_num in range(len(img['sentences'])):\n",
    "        sent = img['sentences'][sent_num]\n",
    "        txt = sent['tokens']\n",
    "#         caption = [w if w in wtoi.keys() else 'UNK' for w in txt]\n",
    "        caption = [w.lower() if w.lower() in wtoi.keys() else 'UNK' for w in txt]\n",
    "        if len(txt) == 0:\n",
    "            print(caption)\n",
    "            caption = ['UNK']\n",
    "            print(caption)\n",
    "#         print(caption)\n",
    "#         pdb.set_trace()\n",
    "        img['final_captions'].append(caption)\n",
    "    \n",
    "    if num % 1000 == 0:\n",
    "        print('processing %d/%d (%.2f%% done)' % (num, len(imgs_vg), num*100.0/len(imgs_vg)))\n",
    "\n",
    "L_vg, label_start_ix_vg, label_end_ix_vg, label_length_vg = labels.encode_captions(imgs_vg, args_vg, wtoi)\n",
    "\n",
    "for img in imgs_vg:\n",
    "    if len(img['sentences']) != len(img['final_captions']):\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_vg[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imgs_sew:\n",
    "    img['final_captions'] = []\n",
    "#     pdb.set_trace()\n",
    "    for sent_num in range(len(img['sentences'])):\n",
    "        sent = img['sentences'][sent_num]\n",
    "        txt = sent['tokens']\n",
    "        caption = [w if w in wtoi.keys() else 'UNK' for w in txt]\n",
    "        if len(txt) == 0:\n",
    "            print(caption)\n",
    "            caption = ['UNK']\n",
    "            print(caption)\n",
    "        img['final_captions'].append(caption)\n",
    "\n",
    "L_sew, label_start_ix_sew, label_end_ix_sew, label_length_sew = labels.encode_captions(imgs_sew, args_sew, wtoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labelfile(L, label_start_ix, label_end_ix, label_length, params, imgs):\n",
    "    # create output h5 file\n",
    "    N = len(imgs)\n",
    "    f_lb = h5py.File(params['output_h5']+'_label.h5', \"w\")\n",
    "    f_lb.create_dataset(\"labels\", dtype='uint32', data=L)\n",
    "    f_lb.create_dataset(\"label_start_ix\", dtype='uint32', data=label_start_ix)\n",
    "    f_lb.create_dataset(\"label_end_ix\", dtype='uint32', data=label_end_ix)\n",
    "    f_lb.create_dataset(\"label_length\", dtype='uint32', data=label_length)\n",
    "    f_lb.close()\n",
    "    print('ok!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json(itow, imgs, params):\n",
    "    out = {}\n",
    "    out['ix_to_word'] = itow # encode the (1-indexed) vocab\n",
    "    out['images'] = []\n",
    "    for i,img in enumerate(imgs):\n",
    "        jimg = {}\n",
    "        jimg['split'] = img['split']\n",
    "        if 'filename' in img: jimg['file_path'] = os.path.join(img['filepath'], img['filename']) # copy it over, might need\n",
    "        if 'cocoid' in img: jimg['id'] = img['cocoid'] # copy over & mantain an id, if present (e.g. coco ids, useful)\n",
    "\n",
    "        out['images'].append(jimg)\n",
    "\n",
    "    json.dump(out, open(params['output_json'], 'w'))\n",
    "    print('wrote ', params['output_json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_labelfile(L, label_start_ix, label_end_ix, label_length, args, imgs)\n",
    "# make_labelfile(L_coco, label_start_ix_coco, label_end_ix_coco, label_length_coco, args_mscoco, imgs_coco)\n",
    "# make_labelfile(L_vg, label_start_ix_vg, label_end_ix_vg, label_length_vg, args_vg, imgs_vg)\n",
    "make_labelfile(L_sew, label_start_ix_sew, label_end_ix_sew, label_length_sew, args_sew, imgs_sew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imgs_vg)):\n",
    "    if len(imgs_vg[i]['final_captions']) != len(info_dataset['images'][i]['sentences']):\n",
    "        print(len(imgs_vg[i]['final_captions']))\n",
    "        print(len(info_dataset['images'][i]['sentences']))\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2204483. 2204484. 2204485. 2204486. 2204487. 2204488. 2204489. 2204490.\n",
      " 2204491. 2204492. 2204493. 2204494. 2204495. 2204496. 2204497. 2204498.\n",
      " 2204499. 2204500. 2204501. 2204502. 2204503. 2204504. 2204505. 2204506.\n",
      " 2204507. 2204508. 2204509. 2204510. 2204511. 2204512. 2204513. 2204514.\n",
      " 2204515. 2204516. 2204517. 2204518. 2204519. 2204520. 2204521. 2204522.\n",
      " 2204523. 2204524. 2204525. 2204526. 2204527.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.]\n",
      "[2204483. 2204484. 2204485. 2204486. 2204487. 2204488. 2204489. 2204490.\n",
      " 2204491. 2204492. 2204493. 2204494. 2204495. 2204496. 2204497. 2204498.\n",
      " 2204499. 2204500. 2204501. 2204502. 2204503. 2204504. 2204505. 2204506.\n",
      " 2204507. 2204508. 2204509. 2204510. 2204511. 2204512. 2204513. 2204514.\n",
      " 2204515. 2204516. 2204517. 2204518. 2204519. 2204520. 2204521. 2204522.\n",
      " 2204523. 2204524. 2204525. 2204526. 2204527.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.]\n",
      "2204483\n",
      "2204527\n"
     ]
    }
   ],
   "source": [
    "# label for each region\n",
    "max_region_num = 88\n",
    "label_start_ix_er = np.zeros((len(label_start_ix_vg), max_region_num))\n",
    "label_end_ix_er = np.zeros((len(label_end_ix_vg), max_region_num))\n",
    "\n",
    "Len = 1\n",
    "for num in range(len(label_start_ix_vg)):\n",
    "    for i, key in enumerate(all_set_regions_nodup[num].keys()):\n",
    "#         if i < 36:\n",
    "        r_len = len(all_set_regions_nodup[num][key])\n",
    "        label_start_ix_er[num, i] += Len\n",
    "        Len += r_len\n",
    "        label_end_ix_er[num, i] += Len - 1\n",
    "    if np.max(label_end_ix_er[num]) != label_end_ix_vg[num]:\n",
    "        pdb.set_trace()\n",
    "print(label_start_ix_er[num])\n",
    "print(label_end_ix_er[num])\n",
    "print(label_start_ix_vg[num])\n",
    "print(label_end_ix_vg[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(imgs_vg)\n",
    "# f_lb = h5py.File('/mnt/workspace2018/nakamura/selfsequential/data/cocotalk_allvg07_larger_label.h5', 'w')\n",
    "# f_lb = h5py.File('/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_vg_larger_label_all.h5', \"w\")\n",
    "f_lb = h5py.File('/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_vg_larger_morethan3gt_label_all.h5', \"w\")\n",
    "f_lb.create_dataset(\"labels\", dtype='uint32', data=L_vg)\n",
    "f_lb.create_dataset(\"label_start_ix\", dtype='uint32', data=label_start_ix_vg)\n",
    "f_lb.create_dataset(\"label_end_ix\", dtype='uint32', data=label_end_ix_vg)\n",
    "f_lb.create_dataset(\"label_length\", dtype='uint32', data=label_length_vg)\n",
    "f_lb.create_dataset(\"label_start_ix_er\", dtype='uint32', data=label_start_ix_er)\n",
    "f_lb.create_dataset(\"label_end_ix_er\", dtype='uint32', data=label_end_ix_er)\n",
    "f_lb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(imgs_sew):\n",
    "    img['filename'] = str(i)\n",
    "    img['cocoid'] = str(i)\n",
    "    img['filepath'] = str(i)\n",
    "    img['imgid'] = str(i)\n",
    "    img['sentids'] = [i]\n",
    "    if (i+1) % 10 == 0:\n",
    "        img['split'] = 'val'\n",
    "    else:\n",
    "        img['split'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_sew[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_json(itow, imgs, args)\n",
    "# make_json(itow, imgs_coco, args_mscoco)\n",
    "make_json(ix_to_word, imgs_vg, args_vg)\n",
    "# make_json(itow, imgs_sew, args_sew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = json.load(open('/mnt/workspace2018/nakamura/IAPR/dataset_iapr.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(info['ix_to_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_list = []\n",
    "for ix in range(len(info['images'])):\n",
    "    try:\n",
    "        A = np.load(os.path.join('/mnt/workspace2018/nakamura/IAPR/features', str(info['images'][ix]['id']) + '.npz' ))\n",
    "    except:\n",
    "        print(info['images'][ix]['id'])\n",
    "        ix_list.append(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ix_list)):\n",
    "    info['images'].pop(ix_list[len(ix_list)-1-i])\n",
    "\n",
    "json.dump(info, open('/mnt/workspace2018/nakamura/IAPR/iapr_talk.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = json.load(open('/mnt/workspace2018/nakamura/IAPR/iapr_talk_mod.json'))\n",
    "# info_coco = json.load(open('/mnt/poplin/share/dataset/MSCOCO/cocotalk_subset_mscoco.json'))\n",
    "import h5py\n",
    "h5_label_file = h5py.File('/mnt/workspace2018/nakamura/IAPR/iaprtalk_mod_label.h5', 'r', driver='core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = h5_label_file['labels']\n",
    "label_start_ix = h5_label_file['label_start_ix'][:]\n",
    "label_end_ix = h5_label_file['label_end_ix'][:]\n",
    "ix_to_word = info['ix_to_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels), len(label_start_ix), len(label_end_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentense(label):\n",
    "    sentense = ''\n",
    "    for word in label:\n",
    "        if word != 0:\n",
    "            sentense += ix_to_word[str(word)] + ' '\n",
    "    print(sentense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentense(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(info['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_coco['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dataset['images'][0]['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "dir = '/mnt/workspace2018/nakamura/IAPR/features/'\n",
    "imgs = []\n",
    "for i ,img in enumerate(info['images']):\n",
    "    path = dir\n",
    "    img_list = os.listdir(path)\n",
    "    if img['id'] + '.npz' in img_list:\n",
    "        img_ = copy.copy(img)\n",
    "        imgs.append(img_)\n",
    "\n",
    "print(len(info['images']))\n",
    "print(len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(info['images']))\n",
    "print(len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['images'] = imgs\n",
    "json.dump(info, open('/mnt/workspace2018/nakamura/IAPR/dataset_iapr_mod.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"coco-caption\")\n",
    "info = json.load(open('/home/nakamura/project/self_seqential/coco-caption/annotations/captions_val2014.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['licenses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['annotations'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
